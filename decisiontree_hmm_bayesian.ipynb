{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Kotak\\Anaconda3\\lib\\site-packages\\sklearn\\cross_validation.py:41: DeprecationWarning: This module was deprecated in version 0.18 in favor of the model_selection module into which all the refactored classes and functions are moved. Also note that the interface of the new CV iterators are different from that of this module. This module will be removed in 0.20.\n",
      "  \"This module will be removed in 0.20.\", DeprecationWarning)\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.cross_validation import train_test_split\n",
    "from sklearn import datasets, svm, cross_validation, tree, preprocessing, metrics\n",
    "import math\n",
    "from random import seed\n",
    "from random import randrange\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.cross_validation import train_test_split\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.metrics import accuracy_score\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>age</th>\n",
       "      <th>sex</th>\n",
       "      <th>cp</th>\n",
       "      <th>trestbps</th>\n",
       "      <th>chol</th>\n",
       "      <th>fbs</th>\n",
       "      <th>restecg</th>\n",
       "      <th>thalach</th>\n",
       "      <th>exang</th>\n",
       "      <th>oldpeak</th>\n",
       "      <th>slope</th>\n",
       "      <th>ca</th>\n",
       "      <th>thal</th>\n",
       "      <th>num</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>63.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>145.0</td>\n",
       "      <td>233.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>150.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.3</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>67.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>160.0</td>\n",
       "      <td>286.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>108.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.5</td>\n",
       "      <td>2.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>67.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>120.0</td>\n",
       "      <td>229.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>129.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.6</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>37.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>130.0</td>\n",
       "      <td>250.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>187.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.5</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>41.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>130.0</td>\n",
       "      <td>204.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>172.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.4</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    age  sex   cp  trestbps   chol  fbs  restecg  thalach  exang  oldpeak  \\\n",
       "0  63.0  1.0  1.0     145.0  233.0  1.0      2.0    150.0    0.0      2.3   \n",
       "1  67.0  1.0  4.0     160.0  286.0  0.0      2.0    108.0    1.0      1.5   \n",
       "2  67.0  1.0  4.0     120.0  229.0  0.0      2.0    129.0    1.0      2.6   \n",
       "3  37.0  1.0  3.0     130.0  250.0  0.0      0.0    187.0    0.0      3.5   \n",
       "4  41.0  0.0  2.0     130.0  204.0  0.0      2.0    172.0    0.0      1.4   \n",
       "\n",
       "   slope   ca thal  num  \n",
       "0    3.0  0.0  6.0    0  \n",
       "1    2.0  3.0  3.0    2  \n",
       "2    2.0  2.0  7.0    1  \n",
       "3    3.0  0.0  3.0    0  \n",
       "4    1.0  0.0  3.0    0  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# ## Load Datasets\n",
    "df1 = pd.read_csv(\"processed.va.csv\",\n",
    "                  names= [\"age\",\"sex\",\"cp\",\"trestbps\",\"chol\",\"fbs\",\"restecg\",\"thalach\",\"exang\",\"oldpeak\",\"slope\",\"ca\",\"thal\",\"num\"])\n",
    "t1 = df1.head()\n",
    "t1.head()\n",
    "\n",
    "df2 = pd.read_csv(\"processed.hungarian.csv\"\n",
    "                  ,names= [\"age\",\"sex\",\"cp\",\"trestbps\",\"chol\",\"fbs\",\"restecg\",\"thalach\",\"exang\",\"oldpeak\",\"slope\",\"ca\",\"thal\",\"num\"])\n",
    "t2 = df2.head()\n",
    "t2.head()\n",
    "\n",
    "df3 = pd.read_csv(\"processed.switzerland.csv\",\n",
    "                  names= [\"age\",\"sex\",\"cp\",\"trestbps\",\"chol\",\"fbs\",\"restecg\",\"thalach\",\"exang\",\"oldpeak\",\"slope\",\"ca\",\"thal\",\"num\"])\n",
    "t3 = df3.head()\n",
    "t3.head()\n",
    "\n",
    "df4 = pd.read_csv(\"processed.cleveland.csv\",\n",
    "                  names= [\"age\",\"sex\",\"cp\",\"trestbps\",\"chol\",\"fbs\",\"restecg\",\"thalach\",\"exang\",\"oldpeak\",\"slope\",\"ca\",\"thal\",\"num\"])\n",
    "t4 = df4.head()\n",
    "t4.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Merge dataframes\n",
    "frames = [df1, df2, df3, df4]\n",
    "all4dataset = pd.concat(frames,axis=0, join='outer', join_axes=None, ignore_index=False,keys=None, \n",
    "                        levels=None, names=None, verify_integrity=False,copy=True)\n",
    "\n",
    "# Analyse null values and their counts for each attribute\n",
    "\n",
    "all4dataset.replace(to_replace=\"NaN\", value=\"[?]\",regex=True, inplace=True)\n",
    "all4dataset.replace(to_replace=\"[?]\", value=np.nan,regex=True, inplace=True)\n",
    "all4dataset.isnull().sum()\n",
    "\n",
    "# Mean and Round the missing values\n",
    "\n",
    "all4dataset.age.replace(to_replace=np.nan, value=all4dataset['age'].mean(axis=0),regex=True, inplace=True)\n",
    "all4dataset.sex.replace(to_replace=np.nan, value=round((all4dataset['sex'].mean(axis=0)),0),regex=True, inplace=True)\n",
    "all4dataset.cp.replace(to_replace=np.nan, value=round((all4dataset['cp'].mean(axis=0)),0),regex=True, inplace=True)\n",
    "\n",
    "p=all4dataset['trestbps']\n",
    "p=p.fillna('0').as_matrix()\n",
    "p=p.astype(np.float)\n",
    "mean=np.mean(p)\n",
    "all4dataset.trestbps.replace(to_replace=np.nan, value=mean,regex=True, inplace=True)\n",
    "\n",
    "p=all4dataset['chol']\n",
    "p=p.fillna('0').as_matrix()\n",
    "p=p.astype(np.float)\n",
    "mean=np.mean(p)\n",
    "all4dataset.chol.replace(to_replace=np.nan, value=mean,regex=True, inplace=True)\n",
    "\n",
    "p=all4dataset['fbs']\n",
    "p=p.fillna('0').as_matrix()\n",
    "p=p.astype(np.float)\n",
    "mean=np.mean(p)\n",
    "all4dataset.fbs.replace(to_replace=np.nan, value=round(mean,0),regex=True, inplace=True)\n",
    "\n",
    "p=all4dataset['restecg']\n",
    "p=p.fillna('0').as_matrix()\n",
    "p=p.astype(np.float)\n",
    "mean=np.mean(p)\n",
    "all4dataset.restecg.replace(to_replace=np.nan, value=round(mean,0),regex=True, inplace=True)\n",
    "\n",
    "p=all4dataset['thalach']\n",
    "p=p.fillna('0').as_matrix()\n",
    "p=p.astype(np.float)\n",
    "mean=np.mean(p)\n",
    "all4dataset.thalach.replace(to_replace=np.nan, value=mean,regex=True, inplace=True)\n",
    "\n",
    "p=all4dataset['exang']\n",
    "p=p.fillna('0').as_matrix()\n",
    "p=p.astype(np.float)\n",
    "mean=np.mean(p)\n",
    "all4dataset.exang.replace(to_replace=np.nan, value=round(mean,0),regex=True, inplace=True)\n",
    "\n",
    "p=all4dataset['oldpeak']\n",
    "p=p.fillna('0').as_matrix()\n",
    "p=p.astype(np.float)\n",
    "mean=np.mean(p)\n",
    "all4dataset.oldpeak.replace(to_replace=np.nan, value=mean,regex=True, inplace=True)\n",
    "\n",
    "p=all4dataset['slope']\n",
    "p=p.fillna('0').as_matrix()\n",
    "p=p.astype(np.float)\n",
    "mean=np.mean(p)\n",
    "all4dataset.slope.replace(to_replace=np.nan, value=round(mean,0),regex=True, inplace=True)\n",
    "\n",
    "p=all4dataset['ca']\n",
    "p=p.fillna('0').as_matrix()\n",
    "p=p.astype(np.float)\n",
    "mean=np.mean(p)\n",
    "all4dataset.ca.replace(to_replace=np.nan, value=round(mean,0),regex=True, inplace=True)\n",
    "\n",
    "p=all4dataset['thal']\n",
    "p=p.fillna('0').as_matrix()\n",
    "p=p.astype(np.float)\n",
    "mean=np.mean(p)\n",
    "all4dataset.thal.replace(to_replace=np.nan, value=round(mean,0),regex=True, inplace=True)\n",
    "\n",
    "p=all4dataset['num']\n",
    "p=p.fillna('0').as_matrix()\n",
    "p=p.astype(np.float)\n",
    "mean=np.mean(p)\n",
    "all4dataset.num.replace(to_replace=np.nan, value=round(mean,0),regex=True, inplace=True)\n",
    "\n",
    "all4dataset=all4dataset.astype(float)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = all4dataset.values[:, 0:12].astype(np.float)\n",
    "Y = all4dataset.values[:, 13].astype(np.float)\n",
    "all_data=all4dataset.values[:, :].astype(np.float)\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, Y, test_size = 0.3, random_state = 100)\n",
    "#print(X_train)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[90 15  7  5  6]\n",
      " [26 45  2  3  5]\n",
      " [ 7 18  1  3  4]\n",
      " [ 6 16  0  1  6]\n",
      " [ 2  5  0  1  2]]\n",
      "HMM accuracy :  50.36231884057971\n"
     ]
    }
   ],
   "source": [
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "from hmmlearn.hmm import GaussianHMM\n",
    "\n",
    "model=GaussianHMM(n_components=5, covariance_type=\"diag\", n_iter=1000).fit(X_train)\n",
    "y_pred = model.predict(X_test)\n",
    "print(confusion_matrix(y_test, y_pred))\n",
    "print(\"HMM accuracy : \",accuracy_score(y_test,y_pred)*100)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Transition matrix\n",
      "[[0.4195108  0.36531679 0.04721331 0.04228593 0.12567317]\n",
      " [0.47436472 0.3653605  0.03786683 0.06091019 0.06149775]\n",
      " [0.5263359  0.20533811 0.07558746 0.04285896 0.14987958]\n",
      " [0.50669144 0.25753628 0.02950501 0.12245471 0.08381255]\n",
      " [0.49427812 0.33696365 0.02316543 0.04177598 0.10381682]]\n"
     ]
    }
   ],
   "source": [
    "print(\"Transition matrix\")\n",
    "print(model.transmat_)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Decision Tree this Fold \n",
      " \n",
      "\n",
      "[X3 < 4.000]\n",
      " [X5 < 126.000]\n",
      "  [X8 < 97.000]\n",
      "   [3.0]\n",
      "   [X4 < 122.000]\n",
      "    [X8 < 141.000]\n",
      "     [1.0]\n",
      "     [3.0]\n",
      "    [X4 < 160.000]\n",
      "     [2.0]\n",
      "     [0.0]\n",
      "  [X10 < 0.800]\n",
      "   [X1 < 57.000]\n",
      "    [X4 < 192.000]\n",
      "     [0.0]\n",
      "     [1.0]\n",
      "    [X8 < 96.000]\n",
      "     [1.0]\n",
      "     [0.0]\n",
      "   [X1 < 70.000]\n",
      "    [X1 < 44.000]\n",
      "     [0.0]\n",
      "     [0.0]\n",
      "    [3.0]\n",
      " [X1 < 60.000]\n",
      "  [X9 < 1.000]\n",
      "   [X5 < 160.000]\n",
      "    [X10 < 1.600]\n",
      "     [1.0]\n",
      "     [2.0]\n",
      "    [X13 < 6.000]\n",
      "     [0.0]\n",
      "     [1.0]\n",
      "   [X13 < 6.000]\n",
      "    [X7 < 1.000]\n",
      "     [1.0]\n",
      "     [1.0]\n",
      "    [X8 < 135.000]\n",
      "     [1.0]\n",
      "     [2.0]\n",
      "  [X4 < 120.000]\n",
      "   [X10 < 2.000]\n",
      "    [1.0]\n",
      "    [2.0]\n",
      "   [X10 < 1.800]\n",
      "    [X2 < 1.000]\n",
      "     [1.0]\n",
      "     [2.0]\n",
      "    [X8 < 102.000]\n",
      "     [3.0]\n",
      "     [3.0]\n",
      "\n",
      " \n",
      "\n",
      "Decision Tree this Fold \n",
      " \n",
      "\n",
      "[X3 < 4.000]\n",
      " [X5 < 100.000]\n",
      "  [X8 < 97.000]\n",
      "   [3.0]\n",
      "   [X4 < 122.000]\n",
      "    [X10 < 0.000]\n",
      "     [0.0]\n",
      "     [1.0]\n",
      "    [X8 < 111.000]\n",
      "     [2.0]\n",
      "     [0.0]\n",
      "  [X1 < 57.000]\n",
      "   [X10 < 0.600]\n",
      "    [X4 < 192.000]\n",
      "     [0.0]\n",
      "     [1.0]\n",
      "    [X10 < 3.000]\n",
      "     [0.0]\n",
      "     [1.0]\n",
      "   [X2 < 1.000]\n",
      "    [X4 < 180.000]\n",
      "     [0.0]\n",
      "     [1.0]\n",
      "    [X1 < 70.000]\n",
      "     [0.0]\n",
      "     [3.0]\n",
      " [X9 < 1.000]\n",
      "  [X5 < 85.000]\n",
      "   [X1 < 59.000]\n",
      "    [X10 < 1.600]\n",
      "     [1.0]\n",
      "     [2.0]\n",
      "    [X7 < 1.000]\n",
      "     [1.0]\n",
      "     [3.0]\n",
      "   [X12 < 1.000]\n",
      "    [X8 < 131.000]\n",
      "     [1.0]\n",
      "     [0.0]\n",
      "    [X4 < 150.000]\n",
      "     [2.0]\n",
      "     [3.0]\n",
      "  [X1 < 63.000]\n",
      "   [X13 < 6.000]\n",
      "    [X7 < 2.000]\n",
      "     [1.0]\n",
      "     [0.0]\n",
      "    [X8 < 135.000]\n",
      "     [1.0]\n",
      "     [2.0]\n",
      "   [X4 < 122.000]\n",
      "    [1.0]\n",
      "    [X5 < 260.000]\n",
      "     [3.0]\n",
      "     [2.0]\n",
      "\n",
      " \n",
      "\n",
      "Decision Tree this Fold \n",
      " \n",
      "\n",
      "[X3 < 4.000]\n",
      " [X5 < 100.000]\n",
      "  [X8 < 97.000]\n",
      "   [3.0]\n",
      "   [X4 < 122.000]\n",
      "    [X10 < 0.000]\n",
      "     [0.0]\n",
      "     [1.0]\n",
      "    [X8 < 111.000]\n",
      "     [2.0]\n",
      "     [0.0]\n",
      "  [X1 < 57.000]\n",
      "   [X10 < 0.600]\n",
      "    [X4 < 192.000]\n",
      "     [0.0]\n",
      "     [1.0]\n",
      "    [X10 < 3.000]\n",
      "     [0.0]\n",
      "     [1.0]\n",
      "   [X2 < 1.000]\n",
      "    [X4 < 180.000]\n",
      "     [0.0]\n",
      "     [1.0]\n",
      "    [X1 < 70.000]\n",
      "     [0.0]\n",
      "     [3.0]\n",
      " [X9 < 1.000]\n",
      "  [X5 < 85.000]\n",
      "   [X1 < 59.000]\n",
      "    [X10 < 1.600]\n",
      "     [1.0]\n",
      "     [2.0]\n",
      "    [X7 < 1.000]\n",
      "     [1.0]\n",
      "     [3.0]\n",
      "   [X12 < 1.000]\n",
      "    [X8 < 131.000]\n",
      "     [1.0]\n",
      "     [0.0]\n",
      "    [X4 < 150.000]\n",
      "     [2.0]\n",
      "     [3.0]\n",
      "  [X1 < 63.000]\n",
      "   [X13 < 6.000]\n",
      "    [X7 < 2.000]\n",
      "     [1.0]\n",
      "     [0.0]\n",
      "    [X8 < 135.000]\n",
      "     [1.0]\n",
      "     [2.0]\n",
      "   [X4 < 122.000]\n",
      "    [1.0]\n",
      "    [X5 < 260.000]\n",
      "     [3.0]\n",
      "     [2.0]\n",
      "\n",
      " \n",
      "\n",
      "Decision Tree this Fold \n",
      " \n",
      "\n",
      "[X3 < 4.000]\n",
      " [X5 < 100.000]\n",
      "  [X8 < 97.000]\n",
      "   [3.0]\n",
      "   [X4 < 122.000]\n",
      "    [X10 < 0.000]\n",
      "     [0.0]\n",
      "     [1.0]\n",
      "    [X8 < 111.000]\n",
      "     [2.0]\n",
      "     [0.0]\n",
      "  [X1 < 57.000]\n",
      "   [X10 < 0.600]\n",
      "    [X4 < 192.000]\n",
      "     [0.0]\n",
      "     [1.0]\n",
      "    [X10 < 3.000]\n",
      "     [0.0]\n",
      "     [1.0]\n",
      "   [X2 < 1.000]\n",
      "    [X4 < 180.000]\n",
      "     [0.0]\n",
      "     [1.0]\n",
      "    [X1 < 70.000]\n",
      "     [0.0]\n",
      "     [3.0]\n",
      " [X9 < 1.000]\n",
      "  [X5 < 85.000]\n",
      "   [X1 < 59.000]\n",
      "    [X10 < 1.600]\n",
      "     [1.0]\n",
      "     [2.0]\n",
      "    [X7 < 1.000]\n",
      "     [1.0]\n",
      "     [3.0]\n",
      "   [X12 < 1.000]\n",
      "    [X8 < 131.000]\n",
      "     [1.0]\n",
      "     [0.0]\n",
      "    [X4 < 150.000]\n",
      "     [2.0]\n",
      "     [3.0]\n",
      "  [X1 < 63.000]\n",
      "   [X13 < 6.000]\n",
      "    [X7 < 2.000]\n",
      "     [1.0]\n",
      "     [0.0]\n",
      "    [X8 < 135.000]\n",
      "     [1.0]\n",
      "     [2.0]\n",
      "   [X4 < 122.000]\n",
      "    [1.0]\n",
      "    [X5 < 260.000]\n",
      "     [3.0]\n",
      "     [2.0]\n",
      "\n",
      " \n",
      "\n",
      "Decision Tree Scores: [55.65217391304348, 65.65217391304347, 61.73913043478261, 63.47826086956522]\n",
      "Decision Tree Mean of 4 Folds Accuracy: 61.630%\n"
     ]
    }
   ],
   "source": [
    "# Evaluate an algorithm using a cross validation using k folds\n",
    "# Calculate accuracy percentage\n",
    "\n",
    "def evaluate_algorithm(dataset, algorithm, n_folds, *args):\n",
    "    dataset_split = list()\n",
    "    dataset_copy = list(dataset)\n",
    "    fold_size = int(len(dataset) / n_folds)\n",
    "    for i in range(n_folds):\n",
    "        fold = list()\n",
    "        while len(fold) < fold_size:\n",
    "            index = randrange(len(dataset_copy))\n",
    "            fold.append(dataset_copy.pop(index))\n",
    "        dataset_split.append(fold)\n",
    "    folds=dataset_split\n",
    "    scores = list()\n",
    "    for fold in folds:\n",
    "        train_set = list(folds)\n",
    "        try:\n",
    "            train_set.remove(fold)\n",
    "        except ValueError:\n",
    "            pass \n",
    "        train_set = sum(train_set, [])\n",
    "        test_set = list()\n",
    "        for row in fold:\n",
    "            row_copy = list(row)\n",
    "            test_set.append(row_copy)\n",
    "            row_copy[-1] = None\n",
    "        predicted = algorithm(train_set, test_set, *args)\n",
    "        actual = [row[-1] for row in fold]\n",
    "        correct = 0\n",
    "        for i in range(len(actual)):\n",
    "            if actual[i] == predicted[i]:\n",
    "                correct += 1\n",
    "        accuracy = (correct / float(len(actual)) * 100.0)\n",
    "        scores.append(accuracy)\n",
    "    return scores\n",
    "\n",
    "# Split a dataset based on an attribute and an attribute value\n",
    "\n",
    "def test_split(index, value, dataset):\n",
    "    left, right = list(), list()\n",
    "    for row in dataset:\n",
    "        if row[index] < value:\n",
    "            left.append(row)\n",
    "        else:\n",
    "            right.append(row)\n",
    "    return left, right\n",
    "\t\n",
    "# Calculate the Gini index for a split dataset\n",
    "# Select the best split point for a dataset\n",
    "\n",
    "def gini_index(groups, classes):\n",
    "    n_instances = float(sum([len(group) for group in groups]))\n",
    "    gini = 0.0\n",
    "    for group in groups:\n",
    "        size = float(len(group))\n",
    "        if size == 0:\n",
    "            continue\n",
    "        score = 0.0\n",
    "        for class_val in classes:\n",
    "            p = [row[-1] for row in group].count(class_val) / size\n",
    "            score += p * p\n",
    "        gini += (1.0 - score) * (size / n_instances)\n",
    "    return gini\n",
    "\n",
    "def get_split(dataset):\n",
    "    class_values = list(set(row[-1] for row in dataset))\n",
    "    b_index, b_value, b_score, b_groups = 999, 999, 999, None\n",
    "    for index in range(len(dataset[0])-1):\n",
    "        for row in dataset:\n",
    "            groups = test_split(index, row[index], dataset)\n",
    "            gini = gini_index(groups, class_values)\n",
    "            if gini < b_score:\n",
    "                b_index, b_value, b_score, b_groups = index, row[index], gini, groups\n",
    "    return {'index':b_index, 'value':b_value, 'groups':b_groups}\n",
    "\n",
    "# Create a terminal node value\n",
    "def to_terminal(group):\n",
    "\toutcomes = [row[-1] for row in group]\n",
    "\treturn max(set(outcomes), key=outcomes.count)\n",
    "\n",
    "# Create child splits for a node or make terminal\n",
    "def split(node, max_depth, min_size, depth):\n",
    "\tleft, right = node['groups']\n",
    "\tdel(node['groups'])\n",
    "\t# check for a no split\n",
    "\tif not left or not right:\n",
    "\t\tnode['left'] = node['right'] = to_terminal(left + right)\n",
    "\t\treturn\n",
    "\t# check for max depth\n",
    "\tif depth >= max_depth:\n",
    "\t\tnode['left'], node['right'] = to_terminal(left), to_terminal(right)\n",
    "\t\treturn\n",
    "\t# process left child\n",
    "\tif len(left) <= min_size:\n",
    "\t\tnode['left'] = to_terminal(left)\n",
    "\telse:\n",
    "\t\tnode['left'] = get_split(left)\n",
    "\t\tsplit(node['left'], max_depth, min_size, depth+1)\n",
    "\t# process right child\n",
    "\tif len(right) <= min_size:\n",
    "\t\tnode['right'] = to_terminal(right)\n",
    "\telse:\n",
    "\t\tnode['right'] = get_split(right)\n",
    "\t\tsplit(node['right'], max_depth, min_size, depth+1)\n",
    "\n",
    "# Build a decision tree\n",
    "def build_tree(train, max_depth, min_size):\n",
    "\troot = get_split(train)\n",
    "\tsplit(root, max_depth, min_size, 1)\n",
    "\treturn root\n",
    "\n",
    "# Make a prediction with a decision tree\n",
    "def predict(node, row):\n",
    "\tif row[node['index']] < node['value']:\n",
    "\t\tif isinstance(node['left'], dict):\n",
    "\t\t\treturn predict(node['left'], row)\n",
    "\t\telse:\n",
    "\t\t\treturn node['left']\n",
    "\telse:\n",
    "\t\tif isinstance(node['right'], dict):\n",
    "\t\t\treturn predict(node['right'], row)\n",
    "\t\telse:\n",
    "\t\t\treturn node['right']\n",
    "\n",
    "# Final Decision Tree Algorithm\n",
    "def print_tree(node, depth=0):\n",
    "\tif isinstance(node, dict):\n",
    "\t\tprint('%s[X%d < %.3f]' % ((depth*' ', (node['index']+1), node['value'])))\n",
    "\t\tprint_tree(node['left'], depth+1)\n",
    "\t\tprint_tree(node['right'], depth+1)\n",
    "\telse:\n",
    "\t\tprint('%s[%s]' % ((depth*' ', node)))\n",
    "    \n",
    "def decision_tree(train, test, max_depth, min_size):\n",
    "    tree = build_tree(train, max_depth, min_size)\n",
    "    print(\"Decision Tree this Fold \\n \\n\")\n",
    "    print_tree(tree)\n",
    "    print(\"\\n \\n\")\n",
    "    predictions = list()\n",
    "    for row in test:\n",
    "        prediction = predict(tree, row)\n",
    "        predictions.append(prediction)\n",
    "    return(predictions)\n",
    "\n",
    "# # Decision Tree call\n",
    "\n",
    "n_folds = 4\n",
    "max_depth = 5\n",
    "min_size = 10\n",
    "scores = evaluate_algorithm(all_data, decision_tree, n_folds, max_depth, min_size)\n",
    "print('Decision Tree Scores: %s' % scores)\n",
    "print('Decision Tree Mean of 4 Folds Accuracy: %.3f%%' % (sum(scores)/float(len(scores))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bayesian Accuracy\n",
      "53.2608695652174\n"
     ]
    }
   ],
   "source": [
    "### Bayesian Classifier\n",
    "def splitDataset(dataset, splitRatio):\n",
    "    trainSize = int(len(dataset) * splitRatio)\n",
    "    trainSet = []\n",
    "    copy = list(dataset)\n",
    "    while len(trainSet) < trainSize:\n",
    "        index = random.randrange(len(copy))\n",
    "        trainSet.append(copy.pop(index))\n",
    "    return [trainSet, copy]\n",
    "\n",
    "def separateByClass(dataset):\n",
    "    separated = {}\n",
    "    for i in range(len(dataset)):\n",
    "        vector = dataset[i]\n",
    "        if (vector[-1] not in separated):\n",
    "            separated[vector[-1]] = []\n",
    "        separated[vector[-1]].append(vector)\n",
    "    return separated\n",
    "\n",
    "def mean(numbers):\n",
    "    return sum(numbers)/float(len(numbers))\n",
    "\n",
    "def stdev(numbers):\n",
    "    avg = mean(numbers)\n",
    "    variance = sum([pow(x-avg,2) for x in numbers])/float(len(numbers)-1)\n",
    "    return math.sqrt(variance)\n",
    "\n",
    "def summarize(dataset):\n",
    "    summaries = [(mean(attribute), stdev(attribute)) for attribute in zip(*dataset)]\n",
    "    del summaries[-1]\n",
    "    return summaries\n",
    "\n",
    "def summarizeByClass(dataset):\n",
    "    separated = separateByClass(dataset)\n",
    "    summaries = {}\n",
    "    for classValue, instances in separated.items():\n",
    "        summaries[classValue] = summarize(instances)\n",
    "    return summaries\n",
    "\n",
    "def calculateProbability(x, mean, stdev):\n",
    "    exponent = math.exp(-(math.pow(x-mean,2)/(2*math.pow(stdev,2))))\n",
    "    return (1 / (math.sqrt(2*math.pi) * stdev)) * exponent\n",
    "\n",
    "def calculateClassProbabilities(summaries, inputVector):\n",
    "    probabilities = {}\n",
    "    for classValue, classSummaries in summaries.items():\n",
    "        probabilities[classValue] = 1\n",
    "        for i in range(len(classSummaries)):\n",
    "            mean, stdev = classSummaries[i]\n",
    "            x = inputVector[i]\n",
    "            probabilities[classValue] *= calculateProbability(x, mean, stdev)\n",
    "    return probabilities\n",
    "\n",
    "def predict(summaries, inputVector):\n",
    "    probabilities = calculateClassProbabilities(summaries, inputVector)\n",
    "    bestLabel, bestProb = None, -1\n",
    "    for classValue, probability in probabilities.items():\n",
    "        if bestLabel is None or probability > bestProb:\n",
    "            bestProb = probability\n",
    "            bestLabel = classValue\n",
    "    return bestLabel\n",
    "\n",
    "def getPredictions(summaries, testSet):\n",
    "    predictions = []\n",
    "    for i in range(len(testSet)):\n",
    "        result = predict(summaries, testSet[i])\n",
    "        predictions.append(result)\n",
    "    return predictions\n",
    "\n",
    "def getAccuracy(testSet, predictions):\n",
    "    correct = 0\n",
    "    for i in range(len(testSet)):\n",
    "        if testSet[i][-1] == predictions[i]:\n",
    "            correct += 1\n",
    "    return (correct/float(len(testSet))) * 100.0\n",
    "\n",
    "# prepare model\n",
    "summaries = summarizeByClass(X_train)\n",
    "# test model\n",
    "predictions = getPredictions(summaries, X_test)\n",
    "accuracy = getAccuracy(X_test, predictions)\n",
    "print(\"Bayesian Accuracy\")\n",
    "print(accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
